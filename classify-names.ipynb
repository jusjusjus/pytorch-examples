{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Names with a Character-Level RNN\n",
    "This code is based on [this](http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) tutorial by Sean Robertson.\n",
    "First download data from [here](https://downloads.pytorch.org/tutorial/data.zip), and unzip to a folder `$HOME/Download/data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import unicodedata\n",
    "from collections import namedtuple\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from os.path import splitext, basename, exists\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "all_letters = string.ascii_lowercase\n",
    "n_letters = len(all_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def uni2ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s).lower()\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "print(uni2ascii('Ślusàrski'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a file and split into lines\n",
    "def read_surnames(filename):\n",
    "    surnames_uni = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [uni2ascii(sur) for sur in surnames_uni]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "index_by_letter = {\n",
    "    letter: i\n",
    "    for i, letter in enumerate(all_letters)\n",
    "}\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def tensor_from_letter(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][index_by_letter[letter.lower()]] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def tensor_from_string(string):\n",
    "    tensor = torch.zeros(len(string), 1, n_letters)\n",
    "    for li, letter in enumerate(string.lower()):\n",
    "        if letter in index_by_letter:\n",
    "            tensor[li][0][index_by_letter[letter]] = 1\n",
    "    return tensor\n",
    "\n",
    "# j = tensor_from_letter('J')\n",
    "# jones = tensor_from_string('Jones')\n",
    "# jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_from_proba(proba):\n",
    "    max_vals, max_idx = proba.data.topk(1) # Tensor out of Variable with .data\n",
    "    lang = max_idx[0][0]\n",
    "    return all_languages[lang], lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_example = namedtuple('example', 'surname language')\n",
    "\n",
    "class Example(_example):\n",
    "\n",
    "    def __new__(self, surname, language=None):\n",
    "        return super().__new__(self, surname, language)\n",
    "    \n",
    "    def features(self, rpad=0):\n",
    "        res = tensor_from_string(self.surname+' '*rpad)\n",
    "        return res.cuda() if cuda else res\n",
    "    \n",
    "    @property\n",
    "    def target(self):\n",
    "        assert self.language is not None\n",
    "        res = torch.LongTensor([all_languages.index(self.language)])\n",
    "        return res.cuda() if cuda else res\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.surname)\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {'features': Variable(self.features()), 'target': self.target}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_namedtuple(cls, s):\n",
    "        return cls(s.surname, s.language)\n",
    "    \n",
    "    def _repr_html_(self):\n",
    "        disp = self.surname\n",
    "        if self.language: disp += \" (language: %s)\"%self.language\n",
    "        return disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurnameDataset(Dataset):\n",
    "    \"\"\"Surname dataset by language/country.\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        series = pd.concat({\n",
    "            target: pd.Series(features)\n",
    "            for target, features in data.items()\n",
    "        })\n",
    "        df = pd.DataFrame(series)\n",
    "        df.columns = ['surname']\n",
    "        df.index.names = ['language', 'number']\n",
    "        df.reset_index(inplace=True)\n",
    "        del df['number']\n",
    "        df['example'] = df.apply(lambda x: Example.from_namedtuple(x), axis=1)\n",
    "        self.languages = np.unique(df.language)\n",
    "        df.reset_index()\n",
    "        self.df = df\n",
    "        self.surnames_by_language = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lang = self.languages[self.rand(len(self.languages))]\n",
    "        surnames = self.surnames_by_language[lang]\n",
    "        surn = surnames[self.rand(len(surnames))]\n",
    "        return Example(surn, lang)\n",
    "#         return self.df.example.iloc[idx]\n",
    "    \n",
    "    def _repr_html_(self):\n",
    "        return self.df._repr_html_()\n",
    "    \n",
    "    def rand(self, n):\n",
    "        return np.random.randint(0, n-1)\n",
    "    \n",
    "    def random_index(self):\n",
    "        lang = self.languages[self.rand(len(self.languages))]\n",
    "        surnames = self.surnames_by_language[lang]\n",
    "        surn = surnames[self.rand(len(surnames))]\n",
    "        dfl = df[(df.language==lang)]\n",
    "        return dfl[(dfl.surname==surn)].index[0]\n",
    "\n",
    "    def random_example(self):\n",
    "        lang = self.languages[self.rand(len(self.languages))]\n",
    "        surnames = self.surnames_by_language[lang]\n",
    "        surn = surnames[self.rand(len(surnames))]\n",
    "        return Example(surn, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(example_list):\n",
    "    ordered = sorted(example_list, key=len, reverse=True)\n",
    "    targets = torch.stack([E.target for E in ordered])\n",
    "    lengths = [len(x) for x in ordered]\n",
    "    max_length = lengths[0]\n",
    "    pads = [max_length-len(x) for x in ordered]\n",
    "    tensors = [E.features(pad) for E, pad in zip(ordered, pads)]\n",
    "    batch = Variable(torch.stack(tensors)).squeeze(2)\n",
    "    features = torch.nn.utils.rnn.pack_padded_sequence(batch, lengths, batch_first=True)\n",
    "    return {'features': features, 'target': targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySampler(torch.utils.data.sampler.Sampler):\n",
    "\n",
    "    def __init__(self, data_source):\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i in range(len(self.data_source)):\n",
    "            yield self.data_source.random_index()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSampler(torch.utils.data.sampler.Sampler):\n",
    "    \"\"\"Samples elements randomly, without replacement.\n",
    "\n",
    "    Arguments:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source):\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(torch.randperm(len(self.data_source)).long())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, X, hidden):\n",
    "        X, hidden = self.rnn(X, hidden)\n",
    "        X, batch_sizes = torch.nn.utils.rnn.pad_packed_sequence(X, batch_first=True)\n",
    "        X = torch.stack([p[i-1] for p, i in zip(X, batch_sizes)])\n",
    "        X = self.softmax(self.linear(X))\n",
    "        return X\n",
    "    \n",
    "    def single(self, x, hidden):\n",
    "        \"\"\"x.shape = torch.size([1, letters_in_word, num_letters])\"\"\"\n",
    "        x, h = self.rnn(x, hidden)\n",
    "        x = self.linear(x[:, -1])\n",
    "        return self.softmax(x)\n",
    "        \n",
    "    def init_hidden(self, batch_size=1):\n",
    "        res = Variable(torch.zeros(1, batch_size, self.hidden_size))\n",
    "        return res.cuda() if cuda else res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the category_lines dictionary, a list of names per language\n",
    "for dir in ('Download', 'Downloads'):\n",
    "    path = os.path.join(os.environ['HOME'], dir)\n",
    "    if os.path.exists(path):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surnames_by_language = {\n",
    "    splitext(basename(filename))[0]: read_surnames(filename)\n",
    "    for filename in glob(os.path.join(path, 'data/names/*.txt'))\n",
    "}\n",
    "\n",
    "all_languages = list(surnames_by_language.keys())\n",
    "n_languages = len(all_languages)\n",
    "n_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_languages)\n",
    "if cuda:\n",
    "    rnn = rnn.cuda()\n",
    "dset = SurnameDataset(surnames_by_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood = nn.NLLLoss()\n",
    "learning_rate = 0.01\n",
    "def train(example):\n",
    "    features, target = example['features'], Variable(example['target'])\n",
    "    batch_size = example['target'].shape[0]\n",
    "    rnn.zero_grad()\n",
    "    logits = rnn(features, rnn.init_hidden(batch_size))\n",
    "#     print('target', target.shape)\n",
    "#     print('logits', logits.shape)\n",
    "    loss = log_likelihood(logits, target.squeeze(1))\n",
    "    loss.backward()\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(-learning_rate/batch_size, p.grad.data)\n",
    "    return logits, loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, epoch = 50, 0\n",
    "print_every = 5000\n",
    "plot_every = 1000\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss, loss = 0, 0\n",
    "all_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# sampler = MySampler(dset)\n",
    "# sampler = RandomSampler(dset)\n",
    "dataloader = DataLoader(dset, batch_size=batch_size, collate_fn=collate, num_workers=0)#, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    current_loss = 0    \n",
    "    for i, example in enumerate(dataloader):\n",
    "        if cuda:\n",
    "            example['features'] = example['features'].cuda()\n",
    "            example['target'] = example['target'].cuda()\n",
    "        this_batch_size = example['target'].shape[0]\n",
    "        opt.zero_grad()\n",
    "        logits = rnn(example['features'], rnn.init_hidden(this_batch_size))\n",
    "        loss = log_likelihood(logits, Variable(example['target']).squeeze(1))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        current_loss += loss*dataloader.batch_size\n",
    "\n",
    "    # Print iter number, loss, name and guess\n",
    "    E = dset.random_example()\n",
    "    proba = rnn.single(Variable(E.features().transpose(0,1)), rnn.init_hidden())\n",
    "    guess, _ = language_from_proba(proba)\n",
    "    correct = '✓' if guess == E.language else '✗ (%s)' % E.language\n",
    "    display('%d %d%% (%s) %.4f %s / %s %s' % (\n",
    "        epoch, epoch / epochs * 100, timeSince(start), loss, E.surname, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    \n",
    "    all_losses.append(current_loss/(dataloader.batch_size*i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterations = 100000\n",
    "# print_every = 5000\n",
    "# plot_every = 1000\n",
    "\n",
    "# # Keep track of losses for plotting\n",
    "# current_loss = 0\n",
    "# all_losses = []\n",
    "# start = time.time()\n",
    "\n",
    "# for epoch in range(1, iterations + 1):\n",
    "#     example = dset.random_example()\n",
    "#     output, loss = train(example.to_dict())\n",
    "#     current_loss += loss\n",
    "\n",
    "#     # Print iter number, loss, name and guess\n",
    "#     if epoch % print_every == 0:\n",
    "#         if epoch % (print_every*5) == 0:\n",
    "#             clear_output()\n",
    "#         guess, guess_i = language_from_proba(output)\n",
    "#         correct = '✓' if guess == example.language else '✗ (%s)' % example.language\n",
    "#         display('%d %d%% (%s) %.4f %s / %s %s' % (\n",
    "#             epoch, epoch / iterations * 100, timeSince(start), loss, example.surname, guess, correct))\n",
    "\n",
    "#     # Add current loss avg to list of losses\n",
    "#     if epoch % plot_every == 0:\n",
    "#         all_losses.append(current_loss / plot_every)\n",
    "#         current_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(all_losses, 'ko-')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of correct guesses in a confusion matrix\n",
    "confusion = torch.zeros(n_languages, n_languages)\n",
    "num_samples = 10000\n",
    "\n",
    "# Go through a bunch of examples and record which are correctly guessed\n",
    "for i in range(num_samples):\n",
    "    if (i%1000) == 0:\n",
    "        print(i)\n",
    "    example = dset.random_example()\n",
    "    var = Variable(example.features().transpose(0, 1))\n",
    "    var = var.cuda() if cuda else var\n",
    "    proba = rnn.single(var, rnn.init_hidden())\n",
    "    \n",
    "    _, guess = language_from_proba(proba)\n",
    "    truth = all_languages.index(example.language)\n",
    "    confusion[truth, guess] += 1\n",
    "\n",
    "# Normalize by dividing every row by its sum\n",
    "for i in range(n_languages):\n",
    "    confusion[i] = confusion[i] / (10**-16+confusion[i].sum())\n",
    "\n",
    "# Set up plot\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set up axes\n",
    "\n",
    "ax.set_xticklabels([''] + all_languages, rotation=90)\n",
    "ax.set_yticklabels([''] + all_languages)\n",
    "\n",
    "# Force label at every tick\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "# sphinx_gallery_thumbnail_number = 2\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
